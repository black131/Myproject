# -*- coding: utf-8 -*-
"""DeepFake Tespiti.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10joFsjt7csYOgcAXlC4YCQFGSSg007PF
"""

import sys
import os
import gc
import random
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from PIL import Image
from tqdm import tqdm
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
import timm
import kagglehub

# --- SİSTEM KONFİGÜRASYONU ---
class Config:
    SEED = 42
    BATCH_SIZE = 32
    IMG_SIZE = 224
    EPOCHS = 3          # Her model için epoch sayısı
    LR = 0.0001         # Öğrenme oranı
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 2     # Veri yükleme işçisi

# Tekrarlanabilirlik için Seed Sabitleme
def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed_everything(Config.SEED)

def log(msg):
    print(f"[SİSTEM] {msg}")
    sys.stdout.flush()

# ==========================================
# 1. VERİ YÖNETİMİ VE HAZIRLIK
# ==========================================
def get_dataset_path():
    log("Veri seti kaynağı kontrol ediliyor...")
    try:
        path = kagglehub.dataset_download("ayushmandatta1/deepdetect-2025")
        base_path = Path(path)
    except:
        base_path = Path("/kaggle/input/deepdetect-2025")

    for root, dirs, files in os.walk(base_path):
        if "train" in dirs:
            return Path(root)

    if (base_path / "train").exists(): return base_path
    if (Path("/kaggle/input/deepdetect-2025/ddata").exists()): return Path("/kaggle/input/deepdetect-2025/ddata")

    raise FileNotFoundError("Kritik Hata: Veri seti bulunamadı.")

DATA_PATH = get_dataset_path()
log(f"Veri Yolu Onaylandı: {DATA_PATH}")

def load_and_split_data():
    log("Veri Entegrasyonu ve Stratified Split işlemi başlatılıyor...")
    all_files, all_labels = [], []

    for split in ["train", "test"]:
        path = DATA_PATH / split
        if not path.exists(): continue
        for label_name, label_idx in [("fake", 0), ("real", 1)]:
            target = path / label_name
            if not target.exists(): target = path / label_name.capitalize()
            if target.exists():
                files = [f for f in target.glob("*.*") if f.suffix.lower() in ['.jpg', '.png', '.jpeg']]
                all_files.extend(files)
                all_labels.extend([label_idx] * len(files))

    # %80 Train, %10 Val, %10 Test
    X_train, X_temp, y_train, y_temp = train_test_split(
        all_files, all_labels, test_size=0.20, stratify=all_labels, random_state=Config.SEED
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=Config.SEED
    )

    log(f"Veri Dağılımı -> Eğitim: {len(X_train)} | Doğrulama: {len(X_val)} | Test: {len(X_test)}")
    return (X_train, y_train), (X_val, y_val), (X_test, y_test)

# ==========================================
# 2. FREKANS VE GÖRÜNTÜ İŞLEME (DSP)
# ==========================================
class DFTTransform:
    def __call__(self, img):
        img_gray = np.array(img.convert('L'))
        f = np.fft.fft2(img_gray)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-9)
        magnitude_spectrum = (magnitude_spectrum - magnitude_spectrum.min()) / (magnitude_spectrum.max() - magnitude_spectrum.min())
        return torch.FloatTensor(magnitude_spectrum).unsqueeze(0)

class DualDomainDataset(Dataset):
    def __init__(self, file_paths, labels, transform=None):
        self.file_paths = file_paths
        self.labels = labels
        self.transform = transform
        self.dft = DFTTransform()

    def __len__(self): return len(self.file_paths)
    def __getitem__(self, idx):
        try:
            img = Image.open(self.file_paths[idx]).convert("RGB")
            freq = self.dft(img)
            if self.transform: img = self.transform(img)
            freq = torch.nn.functional.interpolate(freq.unsqueeze(0), size=(Config.IMG_SIZE, Config.IMG_SIZE), mode='bilinear').squeeze(0)
            return img, freq, self.labels[idx]
        except:
            return torch.zeros((3, Config.IMG_SIZE, Config.IMG_SIZE)), torch.zeros((1, Config.IMG_SIZE, Config.IMG_SIZE)), self.labels[idx]

# ==========================================
# 3. HİBRİT MODEL MİMARİSİ (ENSEMBLE)
# ==========================================
class FreqBranch(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.gap = nn.AdaptiveAvgPool2d((1,1))
    def forward(self, x):
        return torch.flatten(self.gap(self.net(x)), 1)

class BaseModel(nn.Module):
    def __init__(self, backbone, feature_dim, name):
        super().__init__() # Önce burası çalışmalı!
        self.name = name
        self.rgb_backbone = backbone
        self.freq_branch = FreqBranch()
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim + 32, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 1)
        )
    def forward(self, x_rgb, x_freq):
        raise NotImplementedError

# --- Alt Modeller ---
class ModelResNet(BaseModel):
    def __init__(self):
        bb = models.resnet50(weights='DEFAULT')
        dim = bb.fc.in_features
        bb.fc = nn.Identity()
        super().__init__(bb, dim, "ResNet50")
    def forward(self, x, f):
        return self.classifier(torch.cat((torch.flatten(self.rgb_backbone(x), 1), self.freq_branch(f)), 1))

class ModelSwin(BaseModel):
    def __init__(self):
        bb = models.swin_t(weights='DEFAULT')
        dim = bb.head.in_features
        bb.head = nn.Identity()
        super().__init__(bb, dim, "SwinTransformer")
    def forward(self, x, f):
        return self.classifier(torch.cat((self.rgb_backbone(x), self.freq_branch(f)), 1))

# --- DÜZELTİLEN MODEL (MODEL XCEPTION) ---
class ModelXception(BaseModel):
    def __init__(self):
        bb = timm.create_model('xception', pretrained=True)
        dim = bb.num_features
        bb.global_pool = nn.Identity(); bb.fc = nn.Identity()

        # DÜZELTME: Önce Parent Init çağrılmalı, sonra self.pool tanımlanmalı
        super().__init__(bb, dim, "Xception")
        self.pool = nn.AdaptiveAvgPool2d((1, 1))

    def forward(self, x, f):
        feat = self.rgb_backbone(x)
        if len(feat.shape) == 4: feat = self.pool(feat)
        return self.classifier(torch.cat((torch.flatten(feat, 1), self.freq_branch(f)), 1))

class ModelEfficient(BaseModel):
    def __init__(self):
        bb = models.efficientnet_v2_s(weights='DEFAULT')
        dim = bb.classifier[1].in_features
        bb.classifier = nn.Identity()
        super().__init__(bb, dim, "EfficientNetV2")
    def forward(self, x, f):
        return self.classifier(torch.cat((self.rgb_backbone(x), self.freq_branch(f)), 1))

class EnsembleModel(nn.Module):
    def __init__(self, models_list):
        super().__init__()
        self.models = nn.ModuleList(models_list)

    def forward(self, x, f):
        probs = [torch.sigmoid(m(x, f)) for m in self.models]
        return torch.mean(torch.stack(probs), dim=0)

# ==========================================
# 4. EĞİTİM MOTORU
# ==========================================
def train_engine(model_class, train_dl, epochs):
    model = model_class().to(Config.DEVICE)
    name = model.name
    log(f"--- Eğitim Başlıyor: {name} ---")

    opt = optim.Adam(model.parameters(), lr=Config.LR)
    crit = nn.BCEWithLogitsLoss()

    for epoch in range(epochs):
        model.train()
        loop = tqdm(train_dl, desc=f"{name} Ep {epoch+1}/{epochs}", leave=False)
        for img, freq, lbl in loop:
            img, freq, lbl = img.to(Config.DEVICE), freq.to(Config.DEVICE), lbl.to(Config.DEVICE).float().unsqueeze(1)
            opt.zero_grad()
            loss = crit(model(img, freq), lbl)
            loss.backward()
            opt.step()
            loop.set_postfix(loss=loss.item())

    path = f"{name}_best.pth"
    torch.save(model.state_dict(), path)
    log(f"{name} başarıyla kaydedildi.")

    del model, opt
    torch.cuda.empty_cache()
    gc.collect()
    return path

# ==========================================
# 5. ANA YÜRÜTME (MAIN)
# ==========================================
if __name__ == "__main__":
    try:
        # A. Veri Hazırlığı
        (X_tr, y_tr), _, (X_te, y_te) = load_and_split_data()

        transforms_def = transforms.Compose([
            transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.5]*3, [0.5]*3)
        ])

        train_ds = DualDomainDataset(X_tr, y_tr, transforms_def)
        test_ds = DualDomainDataset(X_te, y_te, transforms_def)

        train_dl = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)
        test_dl = DataLoader(test_ds, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS)

        # B. Modellerin Sırayla Eğitilmesi
        paths = []
        paths.append(train_engine(ModelResNet, train_dl, Config.EPOCHS))
        paths.append(train_engine(ModelSwin, train_dl, Config.EPOCHS))
        paths.append(train_engine(ModelXception, train_dl, Config.EPOCHS))
        paths.append(train_engine(ModelEfficient, train_dl, Config.EPOCHS))

        # C. Ensemble Oluşturma ve Yükleme
        log("Ensemble Modeli İnşa Ediliyor...")
        m1 = ModelResNet().to(Config.DEVICE); m1.load_state_dict(torch.load(paths[0]))
        m2 = ModelSwin().to(Config.DEVICE); m2.load_state_dict(torch.load(paths[1]))
        m3 = ModelXception().to(Config.DEVICE); m3.load_state_dict(torch.load(paths[2]))
        m4 = ModelEfficient().to(Config.DEVICE); m4.load_state_dict(torch.load(paths[3]))

        ensemble = EnsembleModel([m1, m2, m3, m4]).to(Config.DEVICE)
        ensemble.eval()

        # D. Final Test ve Raporlama
        log("Final Performans Testi Başlıyor...")
        all_preds, all_labels = [], []

        with torch.no_grad():
            for img, freq, lbl in tqdm(test_dl, desc="Ensemble Test"):
                img, freq = img.to(Config.DEVICE), freq.to(Config.DEVICE)
                preds = (ensemble(img, freq) > 0.5).float().cpu().numpy()
                all_preds.extend(preds.flatten())
                all_labels.extend(lbl.numpy())

        # Görselleştirme
        acc = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)
        log(f"--- FİNAL SONUÇ: %{acc:.2f} ---")

        cm = confusion_matrix(all_labels, all_preds)
        plt.figure(figsize=(8,6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])
        plt.title(f"Hybrid Ensemble Model Confusion Matrix (Acc: {acc:.2f}%)")
        plt.ylabel('Gerçek Etiket')
        plt.xlabel('Tahmin Edilen')
        plt.show()

        print("\n=== DETAYLI SINIFLANDIRMA RAPORU ===")
        print(classification_report(all_labels, all_preds, target_names=['Fake', 'Real']))

    except Exception as e:
        log(f"BEKLENMEDİK HATA: {e}")
        import traceback
        traceback.print_exc()